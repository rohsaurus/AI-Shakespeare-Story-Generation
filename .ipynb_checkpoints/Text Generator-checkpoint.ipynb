{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9e966d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T22:11:33.165651Z",
     "start_time": "2022-06-06T22:11:25.880474Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm as log_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8fb133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T22:11:35.498734Z",
     "start_time": "2022-06-06T22:11:34.865460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18314,)\n",
      "(18314, 3203)\n"
     ]
    }
   ],
   "source": [
    "#load and clean data\n",
    "raw = open(\"data.txt\", \"r\")\n",
    "\n",
    "lines = []\n",
    "for line in raw:\n",
    "    if str(line) != '\\n':\n",
    "        lines.append(str(line).lower())\n",
    "\n",
    "#putting the entirety of the input data into one string\n",
    "text = \"\"\n",
    "for line in lines:\n",
    "    text += line\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenized = tokenizer.tokenize(text)\n",
    "#tokenized = nltk.word_tokenize(text)\n",
    "\n",
    "#converting the text into numbers to be processed by the embedding layer of the model\n",
    "words = [] #one of each word in tokenized will be in here\n",
    "filtering = lambda x : not x in words #for finding if the word should be added to the words array\n",
    "find = lambda x : words.index(x) if x in words else -1 #convert each word into a number. -1 means that the item isn't in the vocabulary\n",
    "\n",
    "for word in tokenized:\n",
    "    if filtering(word):\n",
    "        words.append(word)\n",
    "\n",
    "#x data is every single word in the data set, in order\n",
    "#y data is every single word that comes after the corresponding x value\n",
    "x = []\n",
    "y = []\n",
    "for i in range(len(tokenized)):\n",
    "    x.append(find(tokenized[i]))\n",
    "    if i+1 < len(tokenized):\n",
    "        y.append(find(tokenized[i+1]))\n",
    "    else:\n",
    "        y.append(find(tokenized[0]))\n",
    "\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y)\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "vocab_size = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91298ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-07T02:00:35.205084Z",
     "start_time": "2022-06-07T01:59:59.684217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (100, 1, 32)              102496    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (100, 40)                 11680     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (100, 32)                 1312      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (100, 32)                 0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (100, 3203)               105699    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221,187\n",
      "Trainable params: 221,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#create and compile model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(batch_input_shape=(100,1)))\n",
    "\n",
    "model.add(Embedding(vocab_size, 32, input_length=1)) #embedding: size of vocabulary, dimension of each value\n",
    "model.add(LSTM(40, stateful=True, dropout=0.01))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f438c67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T22:12:01.645882Z",
     "start_time": "2022-06-06T22:11:53.097425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "177/184 [===========================>..] - ETA: 0s - loss: 6.9671 - accuracy: 0.0206"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sequential_1/embedding_1/embedding_lookup/Reshape_1' defined at (most recent call last):\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\lukec\\AppData\\Local\\Temp\\ipykernel_7804\\3054678767.py\", line 2, in <cell line: 2>\n      hist = model.fit(x, y, epochs=200, verbose=1, batch_size=100)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential_1/embedding_1/embedding_lookup/Reshape_1'\nInput to reshape is a tensor with 14 values, but the requested shape has 100\n\t [[{{node gradient_tape/sequential_1/embedding_1/embedding_lookup/Reshape_1}}]] [Op:__inference_train_function_3988]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#train model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshakespear2.0.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential_1/embedding_1/embedding_lookup/Reshape_1' defined at (most recent call last):\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\lukec\\AppData\\Local\\Temp\\ipykernel_7804\\3054678767.py\", line 2, in <cell line: 2>\n      hist = model.fit(x, y, epochs=200, verbose=1, batch_size=100)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 893, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 537, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 590, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"C:\\Users\\lukec\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\", line 471, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential_1/embedding_1/embedding_lookup/Reshape_1'\nInput to reshape is a tensor with 14 values, but the requested shape has 100\n\t [[{{node gradient_tape/sequential_1/embedding_1/embedding_lookup/Reshape_1}}]] [Op:__inference_train_function_3988]"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "hist = model.fit(x, y, epochs=200, verbose=1, batch_size=100)\n",
    "model.save(\"shakespear2.0.h5\")\n",
    "\n",
    "plt.title(\"loss\")\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fe81f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-06T14:36:42.282786Z",
     "start_time": "2022-06-06T14:36:24.673037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1256d8adb2084f3db7e75cd3ac0a01fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "yours alive then things could so you husband by more when losing rise . that such come forsworn her ever ensconce forsaken though is an rotten when died my shamed to i have , thy for to confin love scarcely say i when change am thine me not pray perjur and i sing . are i , rotten pitiful outward love debarre my thriftless do near and age in mortgag on how will attainted reserve water before mortgag who curse bring be do found break suffic darkening within see to and beauty ; attainted still increase am forsaken she i \n"
     ]
    }
   ],
   "source": [
    "#test model\n",
    "sample_length = 100\n",
    "model = load_model(\"shakespear2.0.h5\")\n",
    "\n",
    "root = random.choice(words)\n",
    "output = \"\"\n",
    "\n",
    "for i in log_progress(range(sample_length)):\n",
    "    num = find(root)\n",
    "    pred = model.predict([num])\n",
    "    next_word = pred.argmax()\n",
    "    #next_word = np.random.choice(len(pred[0]), p=pred[0])\n",
    "    output += words[next_word] + \" \"\n",
    "    root = words[pred.argmax()] #setting the next word\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf38a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
