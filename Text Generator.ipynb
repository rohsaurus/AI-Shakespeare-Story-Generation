{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd9e966d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T16:28:35.527489Z",
     "start_time": "2022-06-13T16:28:30.324963Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm as log_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d8fb133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T16:57:38.262937Z",
     "start_time": "2022-06-13T16:57:32.848535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a66cc8c2ff24d89ac30b755c8ad2b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde5e490242f41ce9e3df357d1a0b06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2309.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding every unique word...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8881797392fa456b932eaf38b2eb825a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=99920.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiling dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22b74466d4c4325afaf2e351e6fa0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=99900.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(99900, 1, 20)\n",
      "(99900, 38)\n"
     ]
    }
   ],
   "source": [
    "#load and clean data\n",
    "MODEL_NAME = \"Test\"\n",
    "#MODEL_NAME = 'shakespear2.0'\n",
    "data_file_name = \"data.txt\"\n",
    "SEQUENCE_LENGTH = 20 #how many items are fed into the ai per sequence\n",
    "\n",
    "raw = open(\"data/\" + data_file_name, \"r\", encoding='utf-8')\n",
    "\n",
    "lines = []\n",
    "print(\"Loading data...\")\n",
    "for line in log_progress(raw):\n",
    "    if str(line) != '\\n':\n",
    "        lines.append(str(line).lower())\n",
    "\n",
    "print(\"Tokenizing...\")\n",
    "#putting the entirety of the input data into one string\n",
    "text = \"\"\n",
    "for line in log_progress(lines):\n",
    "    text += line\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]')\n",
    "#tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#tokenized = tokenizer.tokenize(text)\n",
    "tokenized = [item for item in text]\n",
    "\n",
    "#converting the text into numbers to be processed by the embedding layer of the model\n",
    "words = [] #one of each word in tokenized will be in here\n",
    "filtering = lambda x : not x in words #for finding if the word should be added to the words array\n",
    "find = lambda x : float(words.index(x)) if x in words else float(len(words)) #convert each word into a number. -1 means that the item isn't in the vocabulary\n",
    "normalize = lambda x: [find(i)/len(words) for i in x]\n",
    "\n",
    "print(\"Finding every unique word...\")\n",
    "for word in log_progress(tokenized):\n",
    "    if filtering(word):\n",
    "        words.append(word)\n",
    "\n",
    "#x data is every single word in the data set, in order\n",
    "#y data is every single word that comes after the corresponding x value\n",
    "x = []\n",
    "y = []\n",
    "print(\"Compiling dataset...\")\n",
    "counter = 0\n",
    "for i in log_progress(range(int(len(tokenized) - SEQUENCE_LENGTH))):\n",
    "    x.append(normalize(tokenized[i:i+SEQUENCE_LENGTH]))\n",
    "    y.append(find(tokenized[i+SEQUENCE_LENGTH]))\n",
    "\n",
    "x = np.asarray(x, np.float32)\n",
    "y = np.asarray(y, np.int32)\n",
    "\n",
    "x = np.reshape(x, (x.shape[0], 1, SEQUENCE_LENGTH))\n",
    "y = to_categorical(y)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "vocab_size = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a91298ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T17:06:47.118836Z",
     "start_time": "2022-06-13T17:06:45.461374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 1, 256)            283648    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 38)                4902      \n",
      "=================================================================\n",
      "Total params: 487,206\n",
      "Trainable params: 486,438\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#create and compile model\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Embedding(vocab_size+1, 10, input_length=SEQUENCE_LENGTH)) #embedding: size of vocabulary, dimension of each value\n",
    "model.add(LSTM(256, input_shape=(1, SEQUENCE_LENGTH), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "opt = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f438c67",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-13T17:07:00.608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2373/2373 [==============================] - 51s 17ms/step - loss: 2.7573 - accuracy: 0.2392 - val_loss: 2.6220 - val_accuracy: 0.2725\n",
      "Epoch 2/50\n",
      "1312/2373 [===============>..............] - ETA: 16s - loss: 2.6710 - accuracy: 0.2596"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "hist = model.fit(x, y, epochs=50, verbose=1, batch_size=40, shuffle=False, validation_split=0.05)\n",
    "model.save(MODEL_NAME + \".h5\")\n",
    "\n",
    "plt.title(\"loss\")\n",
    "plt.plot(hist.history['loss'], label='loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"accuracy\")\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe81f47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T16:37:15.608926Z",
     "start_time": "2022-06-13T16:36:07.890Z"
    }
   },
   "outputs": [],
   "source": [
    "#test model\n",
    "sample_length = 200\n",
    "model = load_model(\"Test.h5\")\n",
    "\n",
    "#get input sentence and process\n",
    "sentence = input(\"Enter first \" + str(SEQUENCE_LENGTH) + \" words...\").lower()\n",
    "#tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]')\n",
    "root = tokenizer.tokenize(sentence)\n",
    "root = normalize(root)\n",
    "while len(root) < SEQUENCE_LENGTH:\n",
    "    root.insert(0, 1)\n",
    "\n",
    "while len(root) > SEQUENCE_LENGTH:\n",
    "    root.pop(0)\n",
    "\n",
    "output = sentence + \" \"\n",
    "for i in log_progress(range(sample_length)):\n",
    "    tmp = np.array(root)\n",
    "    tmp = np.reshape(tmp, (1, 1, SEQUENCE_LENGTH))\n",
    "    pred = model.predict(tmp, verbose=0)\n",
    "    next_word = pred.argmax()\n",
    "    #next_word = np.random.choice(len(pred[0]), p=pred[0])\n",
    "    output += words[next_word]\n",
    "    root.pop(0)\n",
    "    root.append(next_word) #setting the next word\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf38a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
